{
    "data": {
        "input_size": [64, 64],
        "channels": 3,
        "batch_size": 2,
        "validation_split": 0.2
    },
    "model": {
        "latent_dim": 16,
        "encoder_layers": [
            {"units": 512, "activation": "relu"},
            {"units": 256, "activation": "relu"},
            {"units": 128, "activation": "relu"}
        ],
        "decoder_layers": [
            {"units": 128, "activation": "relu"},
            {"units": 256, "activation": "relu"},
            {"units": 512, "activation": "relu"}
        ]
    },
    "training": {
        "epochs": 100,
        "batch_size": 2,
        "learning_rate": 0.001,
        "optimizer": {
            "type": "adam",
            "beta1": 0.9,
            "beta2": 0.999,
            "epsilon": 1e-8
        }
    },
    "network": {
        "initialization": {
            "type": "xavier",
            "gain": 1.0
        },
        "regularization": {
            "type": "l2",
            "lambda": 1e-4
        }
    },
    "paths": {
        "data_dir": "input/emojis/",
        "save_dir": "output/models/",
        "log_dir": "logs/"
    }
}